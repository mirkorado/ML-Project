{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d8c54d-04c1-44e1-9c0f-c2e79e896a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch                     # for all things PyTorch\n",
    "import torch.nn as nn            # for torch.nn.Module, the parent object for PyTorch models\n",
    "import torch.nn.functional as F  # for the activation function\n",
    "\n",
    "target_path = 'Targets/daily_crsp_sanitized.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579b9f1b-4c11-440a-a1c5-be2f41a10520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>SICCD</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>DlyRet</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>5</td>\n",
       "      <td>15580</td>\n",
       "      <td>6320</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.009549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>7</td>\n",
       "      <td>14593</td>\n",
       "      <td>3573</td>\n",
       "      <td>0</td>\n",
       "      <td>0.088754</td>\n",
       "      <td>-0.009549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>25</td>\n",
       "      <td>62770</td>\n",
       "      <td>6711</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.061489</td>\n",
       "      <td>-0.009549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>29</td>\n",
       "      <td>59184</td>\n",
       "      <td>2082</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.012346</td>\n",
       "      <td>-0.009549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>33</td>\n",
       "      <td>59248</td>\n",
       "      <td>2082</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.034524</td>\n",
       "      <td>-0.009549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  PERMCO  PERMNO  SICCD  NAICS    DlyRet    sprtrn\n",
       "0  2000-01-03       5   15580   6320      0  0.000000 -0.009549\n",
       "1  2000-01-03       7   14593   3573      0  0.088754 -0.009549\n",
       "2  2000-01-03      25   62770   6711      0 -0.061489 -0.009549\n",
       "3  2000-01-03      29   59184   2082      0 -0.012346 -0.009549\n",
       "4  2000-01-03      33   59248   2082      0 -0.034524 -0.009549"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily = pd.read_csv(target_path, nrows=100000)\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8c00a3f-8be0-4957-91c1-012d9ddfadb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>PERMCO</th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>SICCD</th>\n",
       "      <th>NAICS</th>\n",
       "      <th>DlyRet</th>\n",
       "      <th>sprtrn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>34961</td>\n",
       "      <td>86476</td>\n",
       "      <td>6726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>34961</td>\n",
       "      <td>86477</td>\n",
       "      <td>6726</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005618</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>34961</td>\n",
       "      <td>86478</td>\n",
       "      <td>6726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>34961</td>\n",
       "      <td>86479</td>\n",
       "      <td>6726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>2000-01-19</td>\n",
       "      <td>34961</td>\n",
       "      <td>86480</td>\n",
       "      <td>6726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010363</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  PERMCO  PERMNO  SICCD  NAICS    DlyRet    sprtrn\n",
       "99995  2000-01-19   34961   86476   6726      0  0.005405  0.000522\n",
       "99996  2000-01-19   34961   86477   6726      0 -0.005618  0.000522\n",
       "99997  2000-01-19   34961   86478   6726      0  0.015000  0.000522\n",
       "99998  2000-01-19   34961   86479   6726      0  0.014634  0.000522\n",
       "99999  2000-01-19   34961   86480   6726      0  0.010363  0.000522"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d66096-6bfb-47d1-a429-e24a573245be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleMLP(nn.Module):\n",
    "    def __init__(self, layers: list, scale: float=1.):\n",
    "        \"\"\"\n",
    "        param: layers = list of integers\n",
    "        \"\"\"\n",
    "        super(FlexibleMLP, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.activations = nn.ModuleList()\n",
    "\n",
    "        for i in range(len(layers) - 1):\n",
    "            layer = nn.Linear(layers[i], layers[i+1])\n",
    "\n",
    "            # LeCun initialization\n",
    "            nn.init.normal_(layer.weight, mean=0.0, std=scale * np.sqrt(1 / layers[i]))\n",
    "            nn.init.normal_(layer.bias, mean=0.0, std=0 * np.sqrt(1 / layers[i]))\n",
    "\n",
    "            self.layers.append(layer)\n",
    "            # Add ReLU activation after each layer except the last\n",
    "            if i < len(layers) - 2:\n",
    "                self.activations.append(nn.ReLU())\n",
    "            else:\n",
    "                # Placeholder for the last layer's activation\n",
    "                self.activations.append(nn.Identity())\n",
    "\n",
    "    def forward(self, x, return_last_hidden=False):\n",
    "        last_hidden = None\n",
    "\n",
    "        for layer, activation in zip(self.layers[:-1], self.activations[:-1]):\n",
    "            x = activation(layer(x))\n",
    "            last_hidden = x  # Update last_hidden at each hidden layer\n",
    "\n",
    "        # Apply the last layer without ReLU (or Identity for the placeholder)\n",
    "        x = self.layers[-1](x)\n",
    "\n",
    "        if return_last_hidden:\n",
    "            return x, last_hidden\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac118ae-875a-4053-9cbe-325033d5d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loader(signals, returns):\n",
    "  \"\"\"\n",
    "  This is a special DataLoader designed to work with portfolio optimization.\n",
    "  It creates mini-batches using every month of data\n",
    "  \"\"\"\n",
    "  dates = signals.index.get_level_values('date')\n",
    "  unique_dates = dates.unique()\n",
    "  for date in unique_dates:\n",
    "    #print(f'running date {date}')\n",
    "    yield torch.tensor(signals.loc[dates == date].values), torch.tensor(returns.loc[dates == date].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a958bd8-d60c-4c77-818c-883f3b8b3c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_ratio_loss(y_pred, y_true, eps=1e-6):\n",
    "    \"\"\"\n",
    "    Loss function that penalizes low Sharpe ratios.\n",
    "    Args:\n",
    "        y_pred: predicted returns or signals (batch_size x 1)\n",
    "        y_true: actual returns (batch_size x 1)\n",
    "        eps: small value to avoid division by zero\n",
    "    Returns:\n",
    "        loss: negative Sharpe ratio (to be minimized)\n",
    "    \"\"\"\n",
    "    # Portfolio returns if using predictions as weights or expected returns\n",
    "    portfolio_returns = y_pred * y_true\n",
    "\n",
    "    # Mean and standard deviation over the batch\n",
    "    mean_return = portfolio_returns.mean()\n",
    "    std_return = portfolio_returns.std()\n",
    "\n",
    "    sharpe = mean_return / (std_return + eps)\n",
    "\n",
    "    # Negative Sharpe ratio for loss minimization\n",
    "    return -sharpe\n",
    "\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    np.random.seed(seed_value)  # Set NumPy seed\n",
    "    torch.manual_seed(seed_value)  # Set PyTorch seed\n",
    "    random.seed(seed_value)  # Set Python random seed\n",
    "\n",
    "    # If you are using CUDA:\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)  # For multi-GPU\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f38e3c6a-f389-449d-9de5-25e644cf093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = daily['date'].unique()\n",
    "n_train = int(len(unique_dates) * 2 / 3)\n",
    "\n",
    "train_dates = unique_dates[:n_train]\n",
    "test_dates = unique_dates[n_train:]\n",
    "\n",
    "# Split\n",
    "train_df = daily[daily['date'].isin(train_dates)]\n",
    "test_df = daily[daily['date'].isin(test_dates)]\n",
    "\n",
    "# Define features and target\n",
    "features = ['SICCD', 'NAICS', 'sprtrn']  # adjust as needed\n",
    "X_train = train_df[features].fillna(0).values\n",
    "y_train = train_df['DlyRet'].values\n",
    "\n",
    "X_test = test_df[features].fillna(0).values\n",
    "y_test = test_df['DlyRet'].values\n",
    "\n",
    "permno_test = test_df['PERMNO'].values\n",
    "dates_test = test_df['date'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c924a55-affd-43a2-bb4a-bd47c7b3f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae2776d-8065-4f97-bf9c-115041db3628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # output = signal/weight\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b22554-b9cc-45c4-99a8-c20b8a54b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_sharpe_ratio(model, X, y, permno, dates):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(torch.tensor(X, dtype=torch.float32)).numpy()\n",
    "        returns = preds * y\n",
    "\n",
    "        df_eval = pd.DataFrame({\n",
    "            'date': dates,\n",
    "            'permno': permno,\n",
    "            'weighted_ret': returns\n",
    "        })\n",
    "\n",
    "        daily_returns = df_eval.groupby('date')['weighted_ret'].sum()\n",
    "        mean_ret = daily_returns.mean()\n",
    "        std_ret = daily_returns.std()\n",
    "\n",
    "        sharpe = mean_ret / (std_ret + 1e-8)\n",
    "        return sharpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a3fd0d1-a55c-45c6-8905-3b9e8ddbea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Test Sharpe = -4.6729\n",
      "Epoch 1: Test Sharpe = 4.8978\n",
      "Epoch 2: Test Sharpe = -2.9967\n",
      "Epoch 3: Test Sharpe = -3.4349\n",
      "Epoch 4: Test Sharpe = -3.1612\n",
      "Epoch 5: Test Sharpe = -3.0301\n",
      "Epoch 6: Test Sharpe = -3.2513\n",
      "Epoch 7: Test Sharpe = -3.3532\n",
      "Epoch 8: Test Sharpe = -3.4282\n",
      "Epoch 9: Test Sharpe = -3.1661\n",
      "Epoch 10: Test Sharpe = -3.3704\n",
      "Epoch 11: Test Sharpe = -3.1688\n",
      "Epoch 12: Test Sharpe = -3.3443\n",
      "Epoch 13: Test Sharpe = -3.1563\n",
      "Epoch 14: Test Sharpe = -3.2209\n",
      "Epoch 15: Test Sharpe = -3.2618\n",
      "Epoch 16: Test Sharpe = -3.3784\n",
      "Epoch 17: Test Sharpe = -3.1383\n",
      "Epoch 18: Test Sharpe = -2.9974\n",
      "Epoch 19: Test Sharpe = -3.0247\n"
     ]
    }
   ],
   "source": [
    "model = DNN(input_dim=X_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()  # or L1Loss\n",
    "\n",
    "best_sharpe = -np.inf\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(X_batch)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate Sharpe on test set\n",
    "    sharpe = evaluate_sharpe_ratio(model, X_test, y_test, permno_test, dates_test)\n",
    "    print(f\"Epoch {epoch}: Test Sharpe = {sharpe:.4f}\")\n",
    "\n",
    "    if sharpe > best_sharpe:\n",
    "        best_sharpe = sharpe\n",
    "        best_model_state = model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec4f2421-84a4-466c-8eb3-dda3e823355d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Sharpe Ratio: 4.8978\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(best_model_state)\n",
    "print(f\"Best Sharpe Ratio: {best_sharpe:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff788476-6e55-45b5-b1ab-86205a3840cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proceed with the rest of the setup (loss, optimizer) and training loop as before\n",
    "# Loss and optimizer\n",
    "ridge_penalty = 0.01  # Regularization strength\n",
    "set_seed(42)  # Fixing the seed\n",
    "\n",
    "width = 64\n",
    "model = FlexibleMLP([signals.shape[1], width, 1], scale=1.) # re-initializing weights !!!\n",
    "criterion = mssr_loss # this is our custom loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  # Using Adam optimizer for better performance with deep networks\n",
    "\n",
    "# Training loop\n",
    "set_seed(0)  # Fixing the seed\n",
    "num_epochs = 40  # You might need more epochs for a deep network\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader(train_signals, train_returns):\n",
    "        # each mini batch is a month of data\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets) # this is (1- portfolio return)^2\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 2 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
